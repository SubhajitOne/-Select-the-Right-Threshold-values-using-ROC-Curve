{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_classification(n_samples=200,n_features=20,n_classes=2,weights=[1,1],random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 99.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 101.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANhklEQVR4nO3df6zd9V3H8edrXBGZQ370QmqLXkg6XUNiIDeMuWTOdTGDGcofYCDO1aWx2ZxziolU9wdG/wGjQxfJtBm4bpkI4mKbOTXYQdBFqpeB/KpIZVgqld5lgD8WHWRv/zhfl5tyL/fc+z3nXs6nz0fSnHO+53vO9/PpuX322+8559tUFZKktrxhvQcgSRo94y5JDTLuktQg4y5JDTLuktSgqfUeAMCGDRtqZmZmvYchSRPlwQcf/FpVTS923+si7jMzM8zNza33MCRpoiT516Xu87CMJDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg5aNe5LbkxxP8tiCZWcnuSfJU93lWd3yJPlEksNJHklyyTgHL0la3DDfUP008HvAZxYs2w0cqKqbkuzubt8AXA5s6X69FfhkdylJr1szu/983bb9zE3vHcvzLrvnXlX3A18/YfF2YG93fS9w1YLln6mBB4Azk2wc1WAlScNZ7TH386rqGEB3eW63fBPw7IL1jnbLXiXJriRzSebm5+dXOQxJ0mJG/YZqFlm26H/SWlV7qmq2qmanpxc9qZkkaZVWe1bI55NsrKpj3WGX493yo8D5C9bbDDzXZ4DLafFYmST1tdo99/3Aju76DmDfguXv7z41cxnw0v8fvpEkrZ1l99yT3AG8E9iQ5ChwI3ATcFeSncAR4Jpu9S8CVwCHgW8AHxjDmCVJy1g27lV13RJ3bVtk3QI+3HdQkqR+/IaqJDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg3rFPckvJnk8yWNJ7khyWpILkhxM8lSSO5OcOqrBSpKGs+q4J9kE/DwwW1UXAacA1wI3A7dU1RbgBWDnKAYqSRpe38MyU8B3JZkCTgeOAe8C7u7u3wtc1XMbkqQVWnXcq+rfgN8CjjCI+kvAg8CLVfVKt9pRYNNij0+yK8lckrn5+fnVDkOStIg+h2XOArYDFwDfC7wRuHyRVWuxx1fVnqqararZ6enp1Q5DkrSIPodl3g18tarmq+pl4PPADwNndodpADYDz/UcoyRphfrE/QhwWZLTkwTYBjwB3Atc3a2zA9jXb4iSpJXqc8z9IIM3Tr8CPNo91x7gBuD6JIeBc4DbRjBOSdIKTC2/ytKq6kbgxhMWPw1c2ud5JUn9+A1VSWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBvWKe5Izk9yd5J+SHErytiRnJ7knyVPd5VmjGqwkaTh999x/F/jLqvpB4IeAQ8Bu4EBVbQEOdLclSWto1XFPcgbwDuA2gKr6ZlW9CGwH9nar7QWu6jtISdLK9NlzvxCYB/4wyUNJPpXkjcB5VXUMoLs8d7EHJ9mVZC7J3Pz8fI9hSJJO1CfuU8AlwCer6mLgv1nBIZiq2lNVs1U1Oz093WMYkqQT9Yn7UeBoVR3sbt/NIPbPJ9kI0F0e7zdESdJKrTruVfXvwLNJfqBbtA14AtgP7OiW7QD29RqhJGnFpno+/iPA55KcCjwNfIDBXxh3JdkJHAGu6bkNSdIK9Yp7VT0MzC5y17Y+zytJ6sdvqEpSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDXIuEtSg4y7JDWod9yTnJLkoSRf6G5fkORgkqeS3Jnk1P7DlCStxCj23D8KHFpw+2bglqraArwA7BzBNiRJK9Ar7kk2A+8FPtXdDvAu4O5ulb3AVX22IUlaub577r8D/DLwre72OcCLVfVKd/sosGmxBybZlWQuydz8/HzPYUiSFlp13JP8OHC8qh5cuHiRVWuxx1fVnqqararZ6enp1Q5DkrSIqR6PfTtwZZIrgNOAMxjsyZ+ZZKrbe98MPNd/mJKklVj1nntV/UpVba6qGeBa4EtV9ZPAvcDV3Wo7gH29RylJWpFxfM79BuD6JIcZHIO/bQzbkCS9hj6HZb6tqu4D7uuuPw1cOornlSStjt9QlaQGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJatCq457k/CT3JjmU5PEkH+2Wn53kniRPdZdnjW64kqRh9NlzfwX4pap6C3AZ8OEkW4HdwIGq2gIc6G5LktbQquNeVceq6ivd9f8EDgGbgO3A3m61vcBVfQcpSVqZkRxzTzIDXAwcBM6rqmMw+AsAOHeJx+xKMpdkbn5+fhTDkCR1esc9yXcDfwr8QlX9x7CPq6o9VTVbVbPT09N9hyFJWqBX3JN8B4Owf66qPt8tfj7Jxu7+jcDxfkOUJK1Un0/LBLgNOFRVH19w135gR3d9B7Bv9cOTJK3GVI/Hvh34KeDRJA93y34VuAm4K8lO4AhwTb8hSpJWatVxr6q/BbLE3dtW+7ySpP78hqokNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDxhL3JO9J8mSSw0l2j2MbkqSljTzuSU4BbgUuB7YC1yXZOurtSJKWNo4990uBw1X1dFV9E/hjYPsYtiNJWsLUGJ5zE/DsgttHgbeeuFKSXcCu7uZ/JXlyldvbAHxtlY/tJTevx1aBdZzzOnLOJ4eTbs65udecv3+pO8YR9yyyrF61oGoPsKf3xpK5qprt+zyTxDmfHJzzyWFccx7HYZmjwPkLbm8GnhvDdiRJSxhH3P8B2JLkgiSnAtcC+8ewHUnSEkZ+WKaqXknyc8BfAacAt1fV46PezgK9D+1MIOd8cnDOJ4exzDlVrzocLkmacH5DVZIaZNwlqUETE/flTmmQ5DuT3NndfzDJzNqPcrSGmPP1SZ5I8kiSA0mW/MzrpBj21BVJrk5SSSb+Y3PDzDnJT3Sv9eNJ/mitxzhqQ/xsf1+Se5M81P18X7Ee4xyVJLcnOZ7ksSXuT5JPdL8fjyS5pPdGq+p1/4vBG7P/AlwInAr8I7D1hHV+Fvj97vq1wJ3rPe41mPOPAqd31z90Msy5W+9NwP3AA8Dseo97DV7nLcBDwFnd7XPXe9xrMOc9wIe661uBZ9Z73D3n/A7gEuCxJe6/AvgLBt8Tugw42Hebk7LnPswpDbYDe7vrdwPbkiz2hapJseycq+reqvpGd/MBBt8pmGTDnrriN4DfBP5nLQc3JsPM+WeAW6vqBYCqOr7GYxy1YeZcwBnd9e9hwr8rU1X3A19/jVW2A5+pgQeAM5Ns7LPNSYn7Yqc02LTUOlX1CvAScM6ajG48hpnzQjsZ/M0/yZadc5KLgfOr6gtrObAxGuZ1fjPw5iRfTvJAkves2ejGY5g5/xrwviRHgS8CH1mboa2blf55X9Y4Tj8wDsOc0mCo0x5MkKHnk+R9wCzwI2Md0fi95pyTvAG4BfjptRrQGhjmdZ5icGjmnQz+dfY3SS6qqhfHPLZxGWbO1wGfrqrfTvI24LPdnL81/uGti5H3a1L23Ic5pcG310kyxeCfcq/1z6DXu6FO45Dk3cDHgCur6n/XaGzjstyc3wRcBNyX5BkGxyb3T/ibqsP+bO+rqper6qvAkwxiP6mGmfNO4C6Aqvo74DQGJxVr1chP2zIpcR/mlAb7gR3d9auBL1X3TsWEWnbO3SGKP2AQ9kk/DgvLzLmqXqqqDVU1U1UzDN5nuLKq5tZnuCMxzM/2nzF485wkGxgcpnl6TUc5WsPM+QiwDSDJWxjEfX5NR7m29gPv7z41cxnwUlUd6/WM6/0u8grebb4C+GcG77J/rFv26wz+cMPgxf8T4DDw98CF6z3mNZjzXwPPAw93v/av95jHPecT1r2PCf+0zJCvc4CPA08AjwLXrveY12DOW4EvM/gkzcPAj633mHvO9w7gGPAyg730ncAHgQ8ueI1v7X4/Hh3Fz7WnH5CkBk3KYRlJ0goYd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAb9H0yxkhGU5FVwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9326923076923077\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_train_predict = rf.predict_proba(X_train)\n",
    "print(roc_auc_score(y_train,y_train_predict[:,1]))\n",
    "y_test_predict = rf.predict_proba(X_test)\n",
    "print(roc_auc_score(y_test,y_test_predict[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zip(y_train_predict,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.08, 0.92]), 1)\n",
      "(array([0.05, 0.95]), 1)\n",
      "(array([0., 1.]), 1)\n",
      "(array([0.07, 0.93]), 1)\n",
      "(array([0., 1.]), 1)\n",
      "(array([0.15, 0.85]), 1)\n",
      "(array([1., 0.]), 0)\n",
      "(array([0.97, 0.03]), 0)\n",
      "(array([0.92, 0.08]), 0)\n",
      "(array([0.95, 0.05]), 0)\n",
      "(array([0., 1.]), 1)\n",
      "(array([0.05, 0.95]), 1)\n",
      "(array([0.95, 0.05]), 0)\n",
      "(array([0.02, 0.98]), 1)\n",
      "(array([0.17, 0.83]), 1)\n",
      "(array([0.99, 0.01]), 0)\n",
      "(array([0.9, 0.1]), 0)\n",
      "(array([0.08, 0.92]), 1)\n",
      "(array([0.02, 0.98]), 1)\n",
      "(array([0.08, 0.92]), 1)\n",
      "(array([0.09, 0.91]), 1)\n",
      "(array([0.1, 0.9]), 1)\n",
      "(array([0.98, 0.02]), 0)\n",
      "(array([0.96, 0.04]), 0)\n",
      "(array([0.98, 0.02]), 0)\n",
      "(array([0.07, 0.93]), 1)\n",
      "(array([0.96, 0.04]), 0)\n",
      "(array([0.02, 0.98]), 1)\n",
      "(array([0.9, 0.1]), 0)\n",
      "(array([0.02, 0.98]), 1)\n",
      "(array([0.04, 0.96]), 1)\n",
      "(array([0.03, 0.97]), 1)\n",
      "(array([0.96, 0.04]), 0)\n",
      "(array([0.05, 0.95]), 1)\n",
      "(array([0.97, 0.03]), 0)\n",
      "(array([0.02, 0.98]), 1)\n",
      "(array([0.93, 0.07]), 0)\n",
      "(array([0.01, 0.99]), 1)\n",
      "(array([0.9, 0.1]), 0)\n",
      "(array([0.1, 0.9]), 1)\n",
      "(array([0.02, 0.98]), 1)\n",
      "(array([0.93, 0.07]), 0)\n",
      "(array([0.95, 0.05]), 0)\n",
      "(array([0.97, 0.03]), 0)\n",
      "(array([0.06, 0.94]), 1)\n",
      "(array([0.14, 0.86]), 1)\n",
      "(array([0.96, 0.04]), 0)\n",
      "(array([0.18, 0.82]), 1)\n",
      "(array([0.89, 0.11]), 0)\n",
      "(array([0.08, 0.92]), 1)\n",
      "(array([0.05, 0.95]), 1)\n",
      "(array([0.07, 0.93]), 1)\n",
      "(array([0.96, 0.04]), 0)\n",
      "(array([0.9, 0.1]), 0)\n",
      "(array([0.06, 0.94]), 1)\n",
      "(array([0.99, 0.01]), 0)\n",
      "(array([0.87, 0.13]), 0)\n",
      "(array([0.11, 0.89]), 1)\n",
      "(array([0.14, 0.86]), 1)\n",
      "(array([0.04, 0.96]), 1)\n",
      "(array([0.01, 0.99]), 1)\n",
      "(array([0.82, 0.18]), 0)\n",
      "(array([0.94, 0.06]), 0)\n",
      "(array([0.01, 0.99]), 1)\n",
      "(array([0.97, 0.03]), 0)\n",
      "(array([0.03, 0.97]), 1)\n",
      "(array([0.03, 0.97]), 1)\n",
      "(array([0.94, 0.06]), 0)\n",
      "(array([0.04, 0.96]), 1)\n",
      "(array([0.89, 0.11]), 0)\n",
      "(array([0.95, 0.05]), 0)\n",
      "(array([0.98, 0.02]), 0)\n",
      "(array([0.86, 0.14]), 0)\n",
      "(array([0.36, 0.64]), 1)\n",
      "(array([0.07, 0.93]), 1)\n",
      "(array([0., 1.]), 1)\n",
      "(array([0., 1.]), 1)\n",
      "(array([0.95, 0.05]), 0)\n",
      "(array([0.99, 0.01]), 0)\n",
      "(array([0.13, 0.87]), 1)\n",
      "(array([0.87, 0.13]), 0)\n",
      "(array([0.03, 0.97]), 1)\n",
      "(array([0.99, 0.01]), 0)\n",
      "(array([0.97, 0.03]), 0)\n",
      "(array([0.98, 0.02]), 0)\n",
      "(array([0.02, 0.98]), 1)\n",
      "(array([0.1, 0.9]), 1)\n",
      "(array([0.72, 0.28]), 0)\n",
      "(array([0.96, 0.04]), 0)\n",
      "(array([0.21, 0.79]), 1)\n",
      "(array([0.08, 0.92]), 1)\n",
      "(array([0.96, 0.04]), 0)\n",
      "(array([0.03, 0.97]), 1)\n",
      "(array([0., 1.]), 1)\n",
      "(array([0.91, 0.09]), 0)\n",
      "(array([0.92, 0.08]), 0)\n",
      "(array([0.59, 0.41]), 0)\n",
      "(array([0.06, 0.94]), 1)\n",
      "(array([0., 1.]), 1)\n",
      "(array([0.05, 0.95]), 1)\n",
      "(array([0.95, 0.05]), 0)\n",
      "(array([0.97, 0.03]), 0)\n",
      "(array([0.11, 0.89]), 1)\n",
      "(array([0.04, 0.96]), 1)\n",
      "(array([0.08, 0.92]), 1)\n",
      "(array([0.95, 0.05]), 0)\n",
      "(array([0.01, 0.99]), 1)\n",
      "(array([0.15, 0.85]), 1)\n",
      "(array([0.9, 0.1]), 0)\n",
      "(array([0.06, 0.94]), 1)\n",
      "(array([0.91, 0.09]), 0)\n",
      "(array([0.69, 0.31]), 0)\n",
      "(array([0.99, 0.01]), 0)\n",
      "(array([1., 0.]), 0)\n",
      "(array([0.62, 0.38]), 0)\n",
      "(array([0.98, 0.02]), 0)\n",
      "(array([0.03, 0.97]), 1)\n",
      "(array([0.05, 0.95]), 1)\n",
      "(array([0., 1.]), 1)\n",
      "(array([0.96, 0.04]), 0)\n",
      "(array([0.02, 0.98]), 1)\n",
      "(array([0.06, 0.94]), 1)\n",
      "(array([0.05, 0.95]), 1)\n",
      "(array([0.97, 0.03]), 0)\n",
      "(array([0.85, 0.15]), 0)\n",
      "(array([0.95, 0.05]), 0)\n",
      "(array([0.91, 0.09]), 0)\n",
      "(array([0.91, 0.09]), 0)\n",
      "(array([0.06, 0.94]), 1)\n",
      "(array([0.02, 0.98]), 1)\n",
      "(array([0.09, 0.91]), 1)\n",
      "(array([0.06, 0.94]), 1)\n",
      "(array([0.94, 0.06]), 0)\n",
      "(array([0.89, 0.11]), 0)\n",
      "(array([0.88, 0.12]), 0)\n",
      "(array([0.01, 0.99]), 1)\n",
      "(array([0.07, 0.93]), 1)\n",
      "(array([0.05, 0.95]), 1)\n",
      "(array([0.86, 0.14]), 0)\n",
      "(array([0.13, 0.87]), 1)\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9844102564102564\n",
      "0.9581447963800904\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(X_train,y_train)\n",
    "y_train_predict = lg.predict_proba(X_train)\n",
    "print(roc_auc_score(y_train,y_train_predict[:,1]))\n",
    "y_test_predict = lg.predict_proba(X_test)\n",
    "print(roc_auc_score(y_test,y_test_predict[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9751131221719458\n"
     ]
    }
   ],
   "source": [
    "ad = AdaBoostClassifier()\n",
    "ad.fit(X_train,y_train)\n",
    "y_train_predict = ad.predict_proba(X_train)\n",
    "print(roc_auc_score(y_train,y_train_predict[:,1]))\n",
    "y_test_predict = ad.predict_proba(X_test)\n",
    "print(roc_auc_score(y_test,y_test_predict[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751794871794872\n",
      "0.8574660633484162\n"
     ]
    }
   ],
   "source": [
    "kn = KNeighborsClassifier()\n",
    "kn.fit(X_train,y_train)\n",
    "y_train_predict = kn.predict_proba(X_train)\n",
    "print(roc_auc_score(y_train,y_train_predict[:,1]))\n",
    "y_test_predict = kn.predict_proba(X_test)\n",
    "print(roc_auc_score(y_test,y_test_predict[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for model in [rf,lg,ad,kn]:\n",
    "    pred.append(pd.Series(model.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(pred,index=['RandomForest','LogisticRegression','Adaboost','KNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.070233</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.967079</td>\n",
       "      <td>0.943132</td>\n",
       "      <td>0.963135</td>\n",
       "      <td>0.012338</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.968635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864179</td>\n",
       "      <td>0.810013</td>\n",
       "      <td>0.519961</td>\n",
       "      <td>0.943657</td>\n",
       "      <td>0.475844</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.904723</td>\n",
       "      <td>0.931817</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.879520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>0.338226</td>\n",
       "      <td>0.527157</td>\n",
       "      <td>0.378824</td>\n",
       "      <td>0.355288</td>\n",
       "      <td>0.778440</td>\n",
       "      <td>0.720646</td>\n",
       "      <td>0.746343</td>\n",
       "      <td>0.353102</td>\n",
       "      <td>0.301780</td>\n",
       "      <td>0.639402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595887</td>\n",
       "      <td>0.418583</td>\n",
       "      <td>0.439721</td>\n",
       "      <td>0.562088</td>\n",
       "      <td>0.418663</td>\n",
       "      <td>0.360189</td>\n",
       "      <td>0.622196</td>\n",
       "      <td>0.638681</td>\n",
       "      <td>0.335020</td>\n",
       "      <td>0.622096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0         1         2         3         4   \\\n",
       "RandomForest        0.080000  0.320000  0.080000  0.150000  0.880000   \n",
       "LogisticRegression  0.070233  0.000053  0.014947  0.000045  0.967079   \n",
       "Adaboost            0.338226  0.527157  0.378824  0.355288  0.778440   \n",
       "KNN                 0.400000  0.200000  0.000000  0.000000  0.400000   \n",
       "\n",
       "                          5         6         7         8         9   ...  \\\n",
       "RandomForest        0.930000  0.890000  0.060000  0.050000  0.670000  ...   \n",
       "LogisticRegression  0.943132  0.963135  0.012338  0.001578  0.968635  ...   \n",
       "Adaboost            0.720646  0.746343  0.353102  0.301780  0.639402  ...   \n",
       "KNN                 1.000000  1.000000  0.200000  0.400000  0.800000  ...   \n",
       "\n",
       "                          50        51        52        53        54  \\\n",
       "RandomForest        0.730000  0.700000  0.140000  0.800000  0.400000   \n",
       "LogisticRegression  0.864179  0.810013  0.519961  0.943657  0.475844   \n",
       "Adaboost            0.595887  0.418583  0.439721  0.562088  0.418663   \n",
       "KNN                 0.800000  0.600000  0.400000  0.400000  0.600000   \n",
       "\n",
       "                          55        56        57        58        59  \n",
       "RandomForest        0.130000  0.780000  0.680000  0.080000  0.650000  \n",
       "LogisticRegression  0.021645  0.904723  0.931817  0.006195  0.879520  \n",
       "Adaboost            0.360189  0.622196  0.638681  0.335020  0.622096  \n",
       "KNN                 0.200000  0.800000  0.600000  0.200000  0.400000  \n",
       "\n",
       "[4 rows x 60 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.070233</td>\n",
       "      <td>0.338226</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.527157</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.378824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.355288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.967079</td>\n",
       "      <td>0.778440</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.943132</td>\n",
       "      <td>0.720646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.963135</td>\n",
       "      <td>0.746343</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.012338</td>\n",
       "      <td>0.353102</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.301780</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.968635</td>\n",
       "      <td>0.639402</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.510401</td>\n",
       "      <td>0.389723</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.315160</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.970529</td>\n",
       "      <td>0.707837</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.870113</td>\n",
       "      <td>0.768427</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.359977</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.072602</td>\n",
       "      <td>0.382131</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.902974</td>\n",
       "      <td>0.642892</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.997028</td>\n",
       "      <td>0.795148</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.249077</td>\n",
       "      <td>0.420374</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.989020</td>\n",
       "      <td>0.726572</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.469191</td>\n",
       "      <td>0.347022</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.058805</td>\n",
       "      <td>0.456348</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.723751</td>\n",
       "      <td>0.661449</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.994970</td>\n",
       "      <td>0.795148</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.357049</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.909635</td>\n",
       "      <td>0.685775</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.805104</td>\n",
       "      <td>0.473889</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>0.327859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.678541</td>\n",
       "      <td>0.519509</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.287309</td>\n",
       "      <td>0.398704</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.675377</td>\n",
       "      <td>0.618790</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.923379</td>\n",
       "      <td>0.580524</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.885806</td>\n",
       "      <td>0.729721</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.851360</td>\n",
       "      <td>0.440746</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.808183</td>\n",
       "      <td>0.648618</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.891269</td>\n",
       "      <td>0.536381</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.013019</td>\n",
       "      <td>0.373280</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.415275</td>\n",
       "      <td>0.455907</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.604071</td>\n",
       "      <td>0.492704</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.950678</td>\n",
       "      <td>0.716982</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>0.367187</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.522204</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.031568</td>\n",
       "      <td>0.346135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.028392</td>\n",
       "      <td>0.326864</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.367451</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.805044</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.084393</td>\n",
       "      <td>0.337835</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.477139</td>\n",
       "      <td>0.388703</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.823165</td>\n",
       "      <td>0.744008</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.075843</td>\n",
       "      <td>0.399066</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.864179</td>\n",
       "      <td>0.595887</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.810013</td>\n",
       "      <td>0.418583</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.519961</td>\n",
       "      <td>0.439721</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.943657</td>\n",
       "      <td>0.562088</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.475844</td>\n",
       "      <td>0.418663</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.360189</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.904723</td>\n",
       "      <td>0.622196</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.931817</td>\n",
       "      <td>0.638681</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.335020</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.879520</td>\n",
       "      <td>0.622096</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RandomForest  LogisticRegression  Adaboost  KNN\n",
       "0           0.08            0.070233  0.338226  0.4\n",
       "1           0.32            0.000053  0.527157  0.2\n",
       "2           0.08            0.014947  0.378824  0.0\n",
       "3           0.15            0.000045  0.355288  0.0\n",
       "4           0.88            0.967079  0.778440  0.4\n",
       "5           0.93            0.943132  0.720646  1.0\n",
       "6           0.89            0.963135  0.746343  1.0\n",
       "7           0.06            0.012338  0.353102  0.2\n",
       "8           0.05            0.001578  0.301780  0.4\n",
       "9           0.67            0.968635  0.639402  0.8\n",
       "10          0.10            0.510401  0.389723  0.6\n",
       "11          0.26            0.001229  0.315160  0.4\n",
       "12          0.69            0.970529  0.707837  0.4\n",
       "13          0.91            0.870113  0.768427  0.8\n",
       "14          0.13            0.000901  0.359977  0.0\n",
       "15          0.07            0.072602  0.382131  0.0\n",
       "16          0.73            0.902974  0.642892  0.4\n",
       "17          0.98            0.997028  0.795148  1.0\n",
       "18          0.46            0.249077  0.420374  0.8\n",
       "19          0.94            0.989020  0.726572  1.0\n",
       "20          0.09            0.469191  0.347022  0.6\n",
       "21          0.07            0.058805  0.456348  0.2\n",
       "22          0.90            0.723751  0.661449  1.0\n",
       "23          0.99            0.994970  0.795148  1.0\n",
       "24          0.06            0.010114  0.357049  0.2\n",
       "25          0.76            0.909635  0.685775  0.8\n",
       "26          0.70            0.805104  0.473889  0.2\n",
       "27          0.11            0.010073  0.327859  0.0\n",
       "28          0.92            0.678541  0.519509  1.0\n",
       "29          0.08            0.287309  0.398704  0.2\n",
       "30          0.78            0.675377  0.618790  0.8\n",
       "31          0.83            0.923379  0.580524  0.4\n",
       "32          0.76            0.885806  0.729721  0.6\n",
       "33          0.17            0.851360  0.440746  0.6\n",
       "34          0.72            0.808183  0.648618  0.6\n",
       "35          0.95            0.891269  0.536381  0.8\n",
       "36          0.04            0.013019  0.373280  0.2\n",
       "37          0.11            0.415275  0.455907  0.4\n",
       "38          0.83            0.604071  0.492704  0.4\n",
       "39          0.73            0.950678  0.716982  0.6\n",
       "40          0.10            0.008474  0.367187  0.2\n",
       "41          0.14            0.002356  0.522204  0.0\n",
       "42          0.06            0.031568  0.346135  0.0\n",
       "43          0.02            0.028392  0.326864  0.2\n",
       "44          0.08            0.000943  0.367451  0.2\n",
       "45          1.00            0.805044  0.718519  1.0\n",
       "46          0.06            0.084393  0.337835  0.2\n",
       "47          0.22            0.477139  0.388703  0.2\n",
       "48          0.84            0.823165  0.744008  0.8\n",
       "49          0.10            0.075843  0.399066  0.4\n",
       "50          0.73            0.864179  0.595887  0.8\n",
       "51          0.70            0.810013  0.418583  0.6\n",
       "52          0.14            0.519961  0.439721  0.4\n",
       "53          0.80            0.943657  0.562088  0.4\n",
       "54          0.40            0.475844  0.418663  0.6\n",
       "55          0.13            0.021645  0.360189  0.2\n",
       "56          0.78            0.904723  0.622196  0.8\n",
       "57          0.68            0.931817  0.638681  0.6\n",
       "58          0.08            0.006195  0.335020  0.2\n",
       "59          0.65            0.879520  0.622096  0.4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction=pd.concat(pred,axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.222115\n",
       "1     0.261802\n",
       "2     0.118443\n",
       "3     0.126333\n",
       "4     0.756380\n",
       "5     0.898445\n",
       "6     0.899870\n",
       "7     0.156360\n",
       "8     0.188340\n",
       "9     0.769509\n",
       "10    0.400031\n",
       "11    0.244097\n",
       "12    0.692091\n",
       "13    0.837135\n",
       "14    0.122719\n",
       "15    0.131183\n",
       "16    0.668967\n",
       "17    0.943044\n",
       "18    0.482363\n",
       "19    0.913898\n",
       "20    0.376553\n",
       "21    0.196288\n",
       "22    0.821300\n",
       "23    0.945030\n",
       "24    0.156791\n",
       "25    0.788852\n",
       "26    0.544748\n",
       "27    0.111983\n",
       "28    0.779513\n",
       "29    0.241503\n",
       "30    0.718542\n",
       "31    0.683476\n",
       "32    0.743882\n",
       "33    0.515527\n",
       "34    0.694200\n",
       "35    0.794412\n",
       "36    0.156575\n",
       "37    0.345295\n",
       "38    0.581694\n",
       "39    0.749415\n",
       "40    0.168915\n",
       "41    0.166140\n",
       "42    0.109426\n",
       "43    0.143814\n",
       "44    0.162099\n",
       "45    0.880891\n",
       "46    0.170557\n",
       "47    0.321460\n",
       "48    0.801793\n",
       "49    0.243727\n",
       "50    0.747516\n",
       "51    0.632149\n",
       "52    0.374920\n",
       "53    0.676436\n",
       "54    0.473627\n",
       "55    0.177958\n",
       "56    0.776730\n",
       "57    0.712624\n",
       "58    0.155304\n",
       "59    0.637904\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558823529411764\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test,final_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the Roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,threshold = roc_curve(y_test,final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.94502961, 0.94502961, 0.80179306, 0.79441234, 0.78885238,\n",
       "       0.77951257, 0.69209142, 0.68347562, 0.54474829, 0.10942583])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_ls = []\n",
    "for thres in threshold:\n",
    "    y_pred = np.where(final_prediction>thres,1,0)\n",
    "    accu_ls.append(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.566667\n",
       "1    0.566667\n",
       "2    0.700000\n",
       "3    0.716667\n",
       "4    0.700000\n",
       "5    0.716667\n",
       "6    0.850000\n",
       "7    0.866667\n",
       "8    0.933333\n",
       "9    0.450000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(accu_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.945030\n",
       "1    0.945030\n",
       "2    0.801793\n",
       "3    0.794412\n",
       "4    0.788852\n",
       "5    0.779513\n",
       "6    0.692091\n",
       "7    0.683476\n",
       "8    0.544748\n",
       "9    0.109426\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([pd.Series(accu_ls),pd.Series(threshold)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns=['accuracy','threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.544748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.683476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.692091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.794412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.779513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.801793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.788852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.945030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.945030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.109426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  threshold\n",
       "8  0.933333   0.544748\n",
       "7  0.866667   0.683476\n",
       "6  0.850000   0.692091\n",
       "3  0.716667   0.794412\n",
       "5  0.716667   0.779513\n",
       "2  0.700000   0.801793\n",
       "4  0.700000   0.788852\n",
       "0  0.566667   1.945030\n",
       "1  0.566667   0.945030\n",
       "9  0.450000   0.109426"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sort_values(by= 'accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we consider threshold to be 0.544 to get the maximum accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
